<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><!-- hexo injector head_begin start --><script src="https://cdn.jsdelivr.net/npm/echarts@5.5.1/dist/echarts.min.js"></script><!-- hexo injector head_begin end --><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>LeNet5 图像分类（PyTorch 框架） | 梨花先雪</title><meta name="author" content="梨花先雪"><meta name="copyright" content="梨花先雪"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="手撸代码：从零开始的 LeNet5 图像分类（PyTorch 框架）">
<meta property="og:type" content="article">
<meta property="og:title" content="LeNet5 图像分类（PyTorch 框架）">
<meta property="og:url" content="https://haydenzhy.github.io/post/1b5c5745">
<meta property="og:site_name" content="梨花先雪">
<meta property="og:description" content="手撸代码：从零开始的 LeNet5 图像分类（PyTorch 框架）">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/HaydenZHY/jsdelivr@main/image/avatar/avatar2.jpg">
<meta property="article:published_time" content="2024-12-26T00:44:19.000Z">
<meta property="article:modified_time" content="2025-01-02T09:37:48.914Z">
<meta property="article:author" content="梨花先雪">
<meta property="article:tag" content="PyTorch">
<meta property="article:tag" content="LeNet5">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/HaydenZHY/jsdelivr@main/image/avatar/avatar2.jpg"><link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/HaydenZHY/jsdelivr@main/image/avatar/avatar2.jpg"><link rel="canonical" href="https://haydenzhy.github.io/post/1b5c5745"><link rel="preconnect" href="//cdn.jsdelivr.net"/><meta/><meta/><meta/><meta/><meta/><meta/><meta/><meta/><meta/><meta/><meta/><meta/><meta/><meta/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":400},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: 梨花先雪","link":"链接: ","source":"来源: 梨花先雪","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'LeNet5 图像分类（PyTorch 框架）',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-01-02 17:37:48'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 13 || hour >= 13
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.css" /><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"><style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://cdn.jsdelivr.net/gh/HaydenZHY/jsdelivr@main/image/avatar/avatar2.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">50</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">63</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/books/"><i class="fa-fw fa-solid fa-book"></i><span> 书单</span></a></div><div class="menus_item"><a class="site-page" href="/movies/"><i class="fa-fw fa-solid fa-video"></i><span> 电影</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/shuoshuo/"><i class="fa-fw fa-solid fa-comment-dots"></i><span> 说说</span></a></div><div class="menus_item"><a class="site-page" href="/Gallery/"><i class="fa-fw fa-solid fa-image"></i><span> 图库</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fas fa-comment"></i><span> 留言板</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg fixed" id="page-header" style="background: #626079"><nav id="nav"><span id="blog-info"><a href="/" title="梨花先雪"><span class="site-name">梨花先雪</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/books/"><i class="fa-fw fa-solid fa-book"></i><span> 书单</span></a></div><div class="menus_item"><a class="site-page" href="/movies/"><i class="fa-fw fa-solid fa-video"></i><span> 电影</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/shuoshuo/"><i class="fa-fw fa-solid fa-comment-dots"></i><span> 说说</span></a></div><div class="menus_item"><a class="site-page" href="/Gallery/"><i class="fa-fw fa-solid fa-image"></i><span> 图库</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fas fa-comment"></i><span> 留言板</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">LeNet5 图像分类（PyTorch 框架）</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-12-26T00:44:19.000Z" title="发表于 2024-12-26 08:44:19">2024-12-26</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-01-02T09:37:48.914Z" title="更新于 2025-01-02 17:37:48">2025-01-02</time></span></div><div class="meta-secondline"></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1><a target="_blank" rel="noopener" href="https://www.cnblogs.com/xing9/p/17997507/LeNet5-PyTorch" title="发布于 2024-01-31 14:13">手撸代码：从零开始的 LeNet5 图像分类（PyTorch 框架） </a></h1>
<h2 id="摘要："><strong>摘要：</strong></h2>
<p>本文介绍了如何从0开始构建 LeNet5 去识别手写数字（在MNIST数据集上）。代码包括三大部分：<strong>网络</strong>结构部分、<strong>训练</strong>部分、<strong>测试</strong>部分。在编LeNet5部分代码之前，本文详细地梳理了LeNet5的结构，对于初学者十分友好。训练和测试部分也都有详细的代码说明。</p>
<p>在实现 LeNet5 手写数字识别的同时，补充了很多CNN的基础概念和Python编程知识。包括：PyTorch中的常用库和其中的模块，特征图在卷积过程中尺寸如何变化，如何把数据加载进训练程序等。</p>
<p>本文不是通过复制粘贴代码介绍如何实现 LeNet5 的手写数字识别，而是通过内在逻辑，深层次地阐述这一过程，力求“知其然，知其所以然。”</p>
<p>完整代码已经上传至GitHub：<a target="_blank" rel="noopener" href="https://github.com/TiezhuXing01/LeNet5_in_PyTorch.git">https://github.com/TiezhuXing01/LeNet5_in_PyTorch.git</a></p>
<hr>
<p><strong>温馨提示：</strong><br>
（1）本文主要介绍如何从0实现LeNet5，注重编程思路的讲解，对于一些前置知识不做赘述。<br>
（2）请确保你已经<strong>配置好</strong>并进入了深度学习<strong>环境</strong>。<br>
（3）目录导航见页面<strong>右上角</strong>黄色方块。<br>
<strong>前置知识：</strong><br>
（1）概念：PyTorch、卷积、池化、全连接、ReLU、前向传播、反向传播<br>
（2）对python语法有基本的了解</p>
<hr>
<p>在从0开始编程前，我们首先思考一下，一个由LeNet5完成的图像分类任务（如：手写数字识别），都需要哪些组成部分？</p>
<p>首先，肯定要有<strong>LeNet5</strong>网络结构的代码。<br>
其次，还要有在训练集上<strong>训练</strong>的代码，让网络学习特征表示。<br>
最后，训练完要在测试集上<strong>测试</strong>，不然咋知道训练得效果怎样呢？</p>
<hr>
<h2 id="1-引入库（Import-the-Libraries）">1. 引入库（Import the Libraries）</h2>
<p>“库”是一组已经写好的代码，可以理解为一个“工具箱”。对于某些功能的实现，开发者可以从引入的“工具箱”中拿出工具直接使用，而不是从头开始“造工具”（即编代码）。所以在所有工作之前，要把“工具箱”引入进来，以方便后续编程。但有时候，我们引入库时可能会漏掉一些库，在编程到后面才意识到。不用担心，我们再回到开头这里引入库就好了。</p>
<figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p><code>torch</code>库提供了各种用于张量（tensor）操作、神经网络搭建、优化算法等方面的函数。<br>
什么是张量？如果你对张量（tensor）不了解，不用担心，你只需要记住这是图片经过某种处理之后的一种形式，就像你已知的图片有.jpg和.png格式一样。但对于.jpg和.png格式的图像，神经网络并不喜欢，无法直接处理它们。而张量（tensor）这种形式，适用于神经网络的处理。</p>
</li>
<li>
<p><code>torch.nn</code>库可以理解为大工具箱<code>torch</code>里面的小工具箱<code>nn</code>。这个模块里包含构建神经网络层和模型的类和函数。<code>import torch.nn as nn</code>表示，引入之后，模块<code>torch.nn</code>的名字就可以简称<code>nn</code>了。</p>
</li>
<li>
<p><code>torchvision</code>库提供了一系列用于图像处理、计算机视觉数据集加载、图像变换、以及许多流行的计算机视觉模型的实现。</p>
</li>
<li>
<p><code>torchvision.transforms</code>模块用于进行图像的变换和预处理。这个模块包含了一系列用于处理图像的转换函数，可用于数据增强、数据清理和准备图像数据以输入神经网络等任务。</p>
</li>
</ul>
<hr>
<h2 id="2-选择在哪个设备上训练模型（GPU或CPU）">2. 选择在哪个设备上训练模型（GPU或CPU）</h2>
<p>通常情况下，我们都会选择在GPU上训练网络模型，因为神经网络的训练需要大量的计算，而英伟达的GPU提供了CUDA（一个加速计算库）。但如果你的电脑显卡是AMD的，那么有很大概率不支持使用CUDA，此时只能用CPU训练。但在CPU上训练模型是十分缓慢的。如果你暂时没法换电脑，那我建议你去租一个服务器。或者使用阿里云、百度飞桨、谷歌Colab等平台。</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">device</span> = torch.device(<span class="string">&#x27;cuda&#x27;</span> if torch.cuda.is_available() else <span class="string">&#x27;cpu&#x27;</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p><code>torch.cuda.is_available()</code>函数的功能是检查系统中是否安装了可用的 CUDA并且 GPU 是可用的。如果 GPU 可用，返回 True，否则返回 False。</p>
</li>
<li>
<p><code>'cuda' if torch.cuda.is_available() else 'cpu'</code>表示如果GPU可用，则返回字符串<code>'cuda'</code>。如果不可用，则返回字符串<code>'cpu'</code>。</p>
</li>
<li>
<p>如果函数<code>torch.device(...)</code>接收到的是<code>'cuda'</code>，则选择在GPU上计算，如果接收到的是<code>'cpu'</code>，则选择在CPU上进行计算。</p>
</li>
</ul>
<hr>
<h2 id="3-认识网络">3. 认识网络</h2>
<p>充分地认识网络，才能在编程时思路清晰、游刃有余。下图是LeNet5的结构图，请你直观地认识一下LeNet5。如果你不想了解，可以直接去 4. 构建网络，不过我不建议你这样。<br>
本例中LeNet5处理的MNIST数据集图片尺寸都是32×32. 所以下图的输入图片是32×32.</p>
<p><img src="https://s2.loli.net/2024/12/26/QN6wUGncvDbgiyY.png" alt=""></p>
<p>我把上图的网络结构具体为下面的表格，以便我们后续编程。注意：画表格并不是编程所需的必要步骤，只是我希望表达得更清晰。</p>
<table>
<thead>
<tr>
<th>层的名称</th>
<th>具体操作</th>
<th>输入通道数</th>
<th>输出通道数</th>
<th>核或池的尺寸</th>
<th>步幅</th>
</tr>
</thead>
<tbody>
<tr>
<td>卷积层1</td>
<td>卷积</td>
<td>1</td>
<td>6</td>
<td>5×5</td>
<td>1</td>
</tr>
<tr>
<td></td>
<td>批归一化</td>
<td>6</td>
<td>6</td>
<td>–</td>
<td>–</td>
</tr>
<tr>
<td></td>
<td>ReLU</td>
<td>6</td>
<td>6</td>
<td>–</td>
<td>–</td>
</tr>
<tr>
<td>下采样</td>
<td>最大池化</td>
<td>6</td>
<td>6</td>
<td>2×2</td>
<td>2</td>
</tr>
<tr>
<td>卷积层2</td>
<td>卷积</td>
<td>6</td>
<td>16</td>
<td>5×5</td>
<td>1</td>
</tr>
<tr>
<td></td>
<td>批归一化</td>
<td>16</td>
<td>16</td>
<td>–</td>
<td>–</td>
</tr>
<tr>
<td></td>
<td>ReLU</td>
<td>16</td>
<td>16</td>
<td>–</td>
<td>–</td>
</tr>
<tr>
<td>下采样</td>
<td>最大池化</td>
<td>16</td>
<td>16</td>
<td>2×2</td>
<td>2</td>
</tr>
<tr>
<td>全连接层1</td>
<td>全连接</td>
<td>400</td>
<td>120</td>
<td>–</td>
<td>–</td>
</tr>
<tr>
<td></td>
<td>ReLU</td>
<td>120</td>
<td>120</td>
<td>–</td>
<td>–</td>
</tr>
<tr>
<td>全连接层2</td>
<td>全连接</td>
<td>120</td>
<td>84</td>
<td>–</td>
<td>–</td>
</tr>
<tr>
<td></td>
<td>ReLU</td>
<td>84</td>
<td>84</td>
<td>–</td>
<td>–</td>
</tr>
<tr>
<td>高斯连接</td>
<td>全连接</td>
<td>84</td>
<td>类别总数10</td>
<td>–</td>
<td>–</td>
</tr>
</tbody>
</table>
<p>下面我们梳理一下LeNet5的详细流程，这样到后面编程的时候不会懵。</p>
<hr>
<h3 id="（1）卷积层1：提取低级特征">（1）卷积层1：提取低级特征</h3>
<h4 id="a-第一次卷积">a) 第一次卷积</h4>
<p>在图中可以看到，第一次卷积操作之后，不仅通道<strong>由1变6</strong>，原图32×32的尺寸也变成了28×28，这与卷积核大小、步幅和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>a</mi><mi>d</mi><mi>d</mi><mi>i</mi><mi>n</mi><mi>g</mi></mrow><annotation encoding="application/x-tex">padding</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">a</span><span class="mord mathnormal">dd</span><span class="mord mathnormal">in</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span></span></span> 有关（LeNet5中，2次卷积padding都为0）。输出特征图像尺寸公式如下：<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>o</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><mi>t</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo>=</mo><mfrac><mrow><mi>W</mi><mo>−</mo><mi>k</mi><mi>e</mi><mi>r</mi><mi>n</mi><mi>e</mi><mi>l</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo>+</mo><mn>2</mn><mo>∗</mo><mi>p</mi><mi>a</mi><mi>d</mi><mi>d</mi><mi>i</mi><mi>n</mi><mi>g</mi></mrow><mrow><mi>s</mi><mi>t</mi><mi>r</mi><mi>i</mi><mi>d</mi><mi>e</mi></mrow></mfrac><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">output size=\frac{W-kernel size+2*padding}{stride}+1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">tp</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">ze</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2772em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9322em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4461em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">W</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">er</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">ze</span><span class="mbin mtight">+</span><span class="mord mtight">2</span><span class="mbin mtight">∗</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">dd</span><span class="mord mathnormal mtight">in</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span><br>
其中， <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span></span></span> 表示输入图像的宽度。</p>
<p>将数代入公式：<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>o</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><mi>t</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo>=</mo><mfrac><mrow><mn>32</mn><mo>−</mo><mn>5</mn><mo>+</mo><mn>2</mn><mo>∗</mo><mn>0</mn></mrow><mn>1</mn></mfrac><mo>+</mo><mn>1</mn><mo>=</mo><mn>28</mn></mrow><annotation encoding="application/x-tex">output size=\frac{32-5+2*0}{1}+1=28</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">tp</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">ze</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">32</span><span class="mbin mtight">−</span><span class="mord mtight">5</span><span class="mbin mtight">+</span><span class="mord mtight">2</span><span class="mbin mtight">∗</span><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">28</span></span></span></span></p>
<h4 id="b-批归一化">b) 批归一化</h4>
<p>批归一化 (Batch Normalization) 是一种用于提高神经网络训练稳定性和加速收敛的方法。在卷积神经网络中，每个通道都有一个独立的归一化参数。因此输入是6通道，输出还是<strong>6</strong>通道。</p>
<h4 id="c-ReLU激活函数">c) ReLU激活函数</h4>
<p>产生非线性映射，通道数还是<strong>6</strong>，不变。</p>
<hr>
<h3 id="（2）下采样">（2）下采样</h3>
<p>最大池化，通道数不变，还是<strong>6</strong>，特征图尺寸由28×28下降到14×14. 计算公式如下：<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>o</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><mi>t</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo>=</mo><mfrac><mrow><mi>W</mi><mo>−</mo><mi>p</mi><mi>o</mi><mi>o</mi><mi>l</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi></mrow><mrow><mi>s</mi><mi>t</mi><mi>r</mi><mi>i</mi><mi>d</mi><mi>e</mi></mrow></mfrac><mo>+</mo><mn>1</mn><mo>=</mo><mfrac><mrow><mn>28</mn><mo>−</mo><mn>2</mn></mrow><mn>2</mn></mfrac><mo>+</mo><mn>1</mn><mo>=</mo><mn>14</mn></mrow><annotation encoding="application/x-tex">output size=\frac{W-pool size}{stride}+1=\frac{28-2}{2}+1=14</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">tp</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">ze</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2772em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9322em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4461em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">W</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">oo</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">ze</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">28</span><span class="mbin mtight">−</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">14</span></span></span></span></p>
<hr>
<h3 id="（3）卷积层2：提取高级特征">（3）卷积层2：提取高级特征</h3>
<h4 id="a-第二次卷积">a) 第二次卷积</h4>
<p>通道由6变<strong>16</strong>，输出特征图尺寸为10×10.具体计算公式如下：<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>o</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><mi>t</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo>=</mo><mfrac><mrow><mi>W</mi><mo>−</mo><mi>k</mi><mi>e</mi><mi>r</mi><mi>n</mi><mi>e</mi><mi>l</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo>+</mo><mn>2</mn><mo>∗</mo><mi>p</mi><mi>a</mi><mi>d</mi><mi>d</mi><mi>i</mi><mi>n</mi><mi>g</mi></mrow><mrow><mi>s</mi><mi>t</mi><mi>r</mi><mi>i</mi><mi>d</mi><mi>e</mi></mrow></mfrac><mo>+</mo><mn>1</mn><mo>=</mo><mfrac><mrow><mn>14</mn><mo>−</mo><mn>5</mn><mo>+</mo><mn>2</mn><mo>∗</mo><mn>0</mn></mrow><mn>1</mn></mfrac><mo>+</mo><mn>1</mn><mo>=</mo><mn>10</mn></mrow><annotation encoding="application/x-tex">output size=\frac{W-kernel size+2*padding}{stride}+1=\frac{14-5+2*0}{1}+1=10</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">tp</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">ze</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2772em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9322em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4461em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">W</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">er</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">ze</span><span class="mbin mtight">+</span><span class="mord mtight">2</span><span class="mbin mtight">∗</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">dd</span><span class="mord mathnormal mtight">in</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">14</span><span class="mbin mtight">−</span><span class="mord mtight">5</span><span class="mbin mtight">+</span><span class="mord mtight">2</span><span class="mbin mtight">∗</span><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">10</span></span></span></span></p>
<h4 id="b-批归一化-ReLU">b) 批归一化+ReLU</h4>
<p>输出通道还是<strong>16</strong>。</p>
<hr>
<h3 id="（4）下采样">（4）下采样</h3>
<p>特征图尺寸由10×10变成5×5，输出通道还是<strong>16</strong>。<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>o</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><mi>t</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo>=</mo><mfrac><mrow><mi>W</mi><mo>−</mo><mi>p</mi><mi>o</mi><mi>o</mi><mi>l</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi></mrow><mrow><mi>s</mi><mi>t</mi><mi>r</mi><mi>i</mi><mi>d</mi><mi>e</mi></mrow></mfrac><mo>+</mo><mn>1</mn><mo>=</mo><mfrac><mrow><mn>10</mn><mo>−</mo><mn>2</mn></mrow><mn>2</mn></mfrac><mo>+</mo><mn>1</mn><mo>=</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">output size=\frac{W-pool size}{stride}+1=\frac{10-2}{2}+1=5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">tp</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">ze</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2772em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9322em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4461em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">W</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">oo</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">ze</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">10</span><span class="mbin mtight">−</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">5</span></span></span></span></p>
<hr>
<h3 id="（5）全连接层1">（5）全连接层1</h3>
<p>将输入维度为 400 的向量（一维数组）映射到维度为 120 的输出向量。<br>
其中，400为16个通道的5×5大小的所有像素数量。<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>16</mn><mo>∗</mo><mn>5</mn><mo>∗</mo><mn>5</mn><mo>=</mo><mn>400</mn></mrow><annotation encoding="application/x-tex">16*5*5=400</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">16</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">5</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">400</span></span></span></span><br>
120是研究人员通过在实验中不断调整得到的。</p>
<h3 id="（6）全连接层2">（6）全连接层2</h3>
<p>将前一层的 120 个节点映射到 84 个节点。</p>
<h3 id="（7）高斯连接（全连接层3）">（7）高斯连接（全连接层3）</h3>
<p>将84个节点映射到10个具体类别上，即0~9这10个数字上。</p>
<hr>
<h2 id="4-搭建网络">4. 搭建网络</h2>
<p>在搭建之前，我将介绍一个“工具”。<code>nn.Sequential()</code>是 PyTorch 中用于构建容器（container）的类。通俗地讲，这个工具的作用就是把好几个操作串到一起，按顺序执行。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义名为 LeNet5 的类，该类继承自 nn.Module</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LeNet5</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(LeNet5, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="comment"># 卷积层 1</span></span><br><span class="line">        <span class="variable language_">self</span>.layer1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, kernel_size=<span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>),    <span class="comment"># 卷积</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">6</span>),      <span class="comment"># 批归一化</span></span><br><span class="line">            nn.ReLU(),)</span><br><span class="line">        <span class="comment"># 下采样</span></span><br><span class="line">        <span class="variable language_">self</span>.subsampel1 = nn.MaxPool2d(kernel_size = <span class="number">2</span>, stride = <span class="number">2</span>)     <span class="comment"># 最大池化</span></span><br><span class="line">        <span class="comment"># 卷积层 2</span></span><br><span class="line">        <span class="variable language_">self</span>.layer2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, kernel_size=<span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">16</span>),</span><br><span class="line">            nn.ReLU(),)</span><br><span class="line">        <span class="comment"># 下采样</span></span><br><span class="line">        <span class="variable language_">self</span>.subsampel2 = nn.MaxPool2d(kernel_size = <span class="number">2</span>, stride = <span class="number">2</span>)</span><br><span class="line">        <span class="comment"># 全连接</span></span><br><span class="line">        <span class="variable language_">self</span>.L1 = nn.Linear(<span class="number">400</span>, <span class="number">120</span>)</span><br><span class="line">        <span class="variable language_">self</span>.relu = nn.ReLU()</span><br><span class="line">        <span class="variable language_">self</span>.L2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        <span class="variable language_">self</span>.relu1 = nn.ReLU()</span><br><span class="line">        <span class="variable language_">self</span>.L3 = nn.Linear(<span class="number">84</span>, num_classes)</span><br><span class="line">    <span class="comment"># 前向传播</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        out = <span class="variable language_">self</span>.layer1(x)</span><br><span class="line">        out = <span class="variable language_">self</span>.subsampel1(out)</span><br><span class="line">        out = <span class="variable language_">self</span>.layer2(out)</span><br><span class="line">        out = <span class="variable language_">self</span>.subsampel2(out)</span><br><span class="line">        <span class="comment"># 将上一步输出的16个5×5特征图中的400个像素展平成一维向量，以便下一步全连接</span></span><br><span class="line">        out = out.reshape(out.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 全连接</span></span><br><span class="line">        out = <span class="variable language_">self</span>.L1(out)</span><br><span class="line">        out = <span class="variable language_">self</span>.relu(out)</span><br><span class="line">        out = <span class="variable language_">self</span>.L2(out)</span><br><span class="line">        out = <span class="variable language_">self</span>.relu1(out)</span><br><span class="line">        out = <span class="variable language_">self</span>.L3(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<p>发现没有？套路就是：先self.各种层，一顿定义。然后到前向传播（<code>forward</code>）那里，开始用上一步定义的<code>self.something()</code>。最后，<code>return out</code>返回输出值。</p>
<p>对于初学者而言，如果Python基础不牢，最开始那三行代码理解起来可能比较吃力。其实用多了就会发现，这就是个套路，不理解也不耽误编程。</p>
<hr>
<p>此处展开前三行代码</p>
<figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="type">LeNet5</span>(<span class="title">nn</span>.<span class="type">Module</span>):</span></span><br><span class="line"><span class="class">    def __init__(<span class="title">self</span>, <span class="title">num_classes</span>):</span></span><br><span class="line"><span class="class">        super(<span class="type">LeNet5</span>, <span class="title">self</span>).__init__()</span></span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>我们来看第一行代码。这行代码定义了一个名为 <code>LeNet5</code> 的类，它继承自 <code>nn.Module</code>（别忘了，在最开始引入库时，引入过<code>nn</code>），说明这是一个 PyTorch 框架中神经网络模型的基类。所有的神经网络模型都应该继承自 <code>nn.Module</code>，这样它们就能够利用 PyTorch 提供的模型管理和训练的功能。</p>
</li>
<li>
<p>第二行代码：是类的构造函数（initializer）。构造函数用于初始化类的实例。<code>num_classes</code>是类别数，这里是我们构造的网络所接收的参数，后续要用到这个参数。</p>
</li>
<li>
<p>第三行代码：调用了父类 <code>nn.Module</code> 的构造函数，确保正确地初始化 LeNet5 类的父类部分。这是 Python 中用于调用父类方法的一种方式。</p>
</li>
</ul>
<p>如果读完这些解释还是不理解，没关系，你可以把这三行当作一个套路，用多了自然就会记住。</p>
<p>套路如下：</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> 网络名字(nn.<span class="title class_">Module</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"><span class="variable language_">self</span>, 需要接受的参数</span>)：</span><br><span class="line">        <span class="variable language_">super</span>(网络名字, <span class="variable language_">self</span>).__init__()</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="5-准备（加载）数据集">5. 准备（加载）数据集</h2>
<p>在上一步中，LeNet5已经搭建好了，现在该编写训练部分的程序了。但是在这之前有一步不能落下，那就是数据加载。</p>
<p>要把数据集里的一堆数据“码好”了，一批一批地“喂”给LeNet5.</p>
<p>MNIST 数据集是一个手写数字图像数据集，包含了大量的手写数字图片，每张图片都标注了对应的数字。<br>
<code>torchvision.datasets.MNIST(...)</code>是 PyTorch 中用于加载 MNIST 数据集的类。<br>
<code>torch.utils.data.DataLoader(...)</code> 是 PyTorch 中用于批量加载数据的工具类，是一个数据加载器。</p>
<p>注意：前者用于加载数据<strong>集</strong>，后者用于加载数据，不要混淆。</p>
<p>把一个数据集比作一副扑克牌，那么一张扑克牌就是一个数据。把DataLoader比作神经网络的手，手去抓牌。一次抓几张，抓牌有没有顺序，等等，这些都是通过设置DataLoader的参数决定的。batch_size等于几就是一次抓几张牌，即一次“喂”给神经网络几张图片。</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载训练集</span></span><br><span class="line"><span class="attr">train_dataset</span> = torchvision.datasets.MNIST(root = <span class="string">&#x27;./data&#x27;</span>, <span class="comment"># 数据集保存路径</span></span><br><span class="line">                                           <span class="attr">train</span> = <span class="literal">True</span>,    <span class="comment"># 是否为训练集</span></span><br><span class="line">                                           <span class="comment"># 数据预处理</span></span><br><span class="line">                                           <span class="attr">transform</span> = transforms.Compose([</span><br><span class="line">                                                  transforms.Resize((<span class="number">32</span>,<span class="number">32</span>)),</span><br><span class="line">                                                  transforms.ToTensor(),</span><br><span class="line">                                                  transforms.Normalize(mean = (<span class="number">0.1307</span>,), </span><br><span class="line">                                                                     std = (<span class="number">0.3081</span>,))]),</span><br><span class="line">                                           <span class="attr">download</span> = <span class="literal">True</span>) <span class="comment">#是否下载</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载测试集</span></span><br><span class="line"><span class="attr">test_dataset</span> = torchvision.datasets.MNIST(root = <span class="string">&#x27;./data&#x27;</span>,</span><br><span class="line">                                          <span class="attr">train</span> = <span class="literal">False</span>,</span><br><span class="line">                                          <span class="attr">transform</span> = transforms.Compose([</span><br><span class="line">                                                  transforms.Resize((<span class="number">32</span>,<span class="number">32</span>)),</span><br><span class="line">                                                  transforms.ToTensor(),</span><br><span class="line">                                                  transforms.Normalize(mean = (<span class="number">0.1325</span>,), </span><br><span class="line">                                                                     std = (<span class="number">0.3105</span>,))]),</span><br><span class="line">                                          <span class="attr">download</span>=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 一次抓64张牌</span></span><br><span class="line"><span class="attr">batch_size</span> = <span class="number">64</span></span><br><span class="line"><span class="comment"># 加载训练数据</span></span><br><span class="line"><span class="attr">train_loader</span> = torch.utils.data.DataLoader(dataset = train_dataset,</span><br><span class="line">                                           <span class="attr">batch_size</span> = batch_size,</span><br><span class="line">                                           <span class="attr">shuffle</span> = <span class="literal">True</span>)  <span class="comment"># 是否打乱</span></span><br><span class="line"><span class="comment"># 加载测试数据</span></span><br><span class="line"><span class="attr">test_loader</span> = torch.utils.data.DataLoader(dataset = test_dataset,</span><br><span class="line">                                           <span class="attr">batch_size</span> = batch_size,</span><br><span class="line">                                           <span class="attr">shuffle</span> = <span class="literal">False</span>) <span class="comment"># 是否打乱</span></span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>训练阶段的<code>shuffle=True</code>：将数据集打乱顺序，有助于模型学习更泛化的特征。通过打乱数据顺序，模型在每个 epoch 中都能够看到不同的样本，防止模型过度拟合训练集中的特定顺序。</p>
</li>
<li>
<p>测试阶段的<code>shuffle=False</code>：在测试阶段，通常不需要打乱数据的顺序。测试时模型是在未见过的数据上进行评估，因此希望模型看到的是原始数据的有序顺序，以便能够更好地评估模型的泛化性能。如果在测试时也打乱数据，可能会导致模型在评估时看到的数据分布与实际场景不一致。（其实如果是<code>True</code>影响也不大）</p>
</li>
</ul>
<hr>
<h2 id="6-设置超参数">6. 设置超参数</h2>
<p>在训练之前，我们需要设置一些超参数，为训练阶段要用到的模型、损失函数、优化器做准备。</p>
<h3 id="（1）创建-LeNet5-模型">（1）创建 LeNet5 模型</h3>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">num_classes</span> = <span class="number">10</span></span><br><span class="line"><span class="attr">model</span> = LeNet5(num_classes).to(device)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>LeNet5(num_classes)</code>：创建一个 LeNet5 类的实例。还记得么？前文提到过，该类是继承自 nn.Module 的神经网络模型，接受 num_classes 参数，表示模型输出的类别数目。</li>
<li><code>to(device)</code>：将模型移动到指定的设备上，其中 <code>device</code> 是一个设备对象，可以是 <code>'cuda'</code>（GPU）或者 <code>'cpu'</code>。这一步是为了确保模型在训练和推理时使用的是正确的计算设备。</li>
<li><code>model = ...</code>：将创建并移动到指定设备的模型赋值给变量 model，以便后续对模型的引用和操作。</li>
</ul>
<h3 id="（2）创建损失函数">（2）创建损失函数</h3>
<p>在这里，损失函数设置为交叉熵损失函数</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">cost</span> = nn.CrossEntropyLoss()</span><br></pre></td></tr></table></figure>
<ul>
<li><code>nn.CrossEntropyLoss()</code>是 PyTorch 中用于计算多类别交叉熵损失的损失函数。交叉熵损失通常用于分类问题，特别是当目标是多类别标签时。它的计算涉及到模型的预测值和实际类别标签之间的比较，以衡量模型输出与真实标签之间的差异。</li>
</ul>
<h3 id="（3）创建优化器">（3）创建优化器</h3>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">learning_rate</span> = <span class="number">0.001</span></span><br><span class="line"><span class="attr">optimizer</span> = torch.optim.Adam(model.parameters(), lr=learning_rate)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>torch.optim.Adam</code>：这是 PyTorch 中提供的 Adam 优化器的实现。Adam 是一种常用的随机梯度下降算法的变体，它通过自适应地调整学习率来优化模型参数。</li>
<li><code>model.parameters()</code>：指定要被优化的参数，就是告诉优化器去优化谁，这里选择了模型 model 中的所有参数。</li>
<li><code>lr=learning_rate</code>：设置学习率，即每次参数更新时的步进大小。</li>
</ul>
<h3 id="（4）确定每轮共需几步">（4）确定每轮共需几步</h3>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">total_step</span> = len(train_loader)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>len(train_loader) </code>返回加载器中的批次数量。</li>
<li>MNIST数据集中有 60000 张图片作为训练集。我们每次抓64张牌，那么一共要抓 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>60000</mn><mn>64</mn></mfrac><mo>=</mo><mn>937.5</mn></mrow><annotation encoding="application/x-tex">\frac{60000}{64}=937.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">64</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">60000</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">937.5</span></span></span></span> ，937.5 向上取整是 938 个批次。也就是说，由于数据加载器DataLoader的存在，LeNet5 把训练集所有图片遍历一遍要 938 步（step）。训练一轮（epoch）需要 938 步（step）。总结一下，一轮需要很多步，<strong>一步就是一个批次</strong>。</li>
</ul>
<hr>
<h2 id="7-训练">7. 训练</h2>
<p>我们将用 2 个 for 循环的嵌套来实现训练过程。</p>
<p>先让我们梳理一下应该如何训练。首先，训练分很多轮（epoch），每轮训练都需要把全部训练集过一遍。所以需要一个 for 循环，一轮一轮地进行循环。这个“过一遍”是通过数据加载器 DataLoader 实现的。其次，在一轮训练中，完整遍历一次训练集需要一个 for 循环，去循环从 DataLoader 加载过来的每个批次的图片（本例为64张图）。</p>
<p>在本例中，我设置共训练 10 轮。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置一共训练几轮（epoch）</span></span><br><span class="line">num_epochs = <span class="number">10</span></span><br><span class="line"><span class="comment"># 外部循环用于遍历轮次</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="comment"># 内部循环用于遍历每轮中的所有批次</span></span><br><span class="line">    <span class="keyword">for</span> i, (images, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):  </span><br><span class="line">        images = images.to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 前向传播</span></span><br><span class="line">        outputs = model(images)   <span class="comment"># 通过模型进行前向传播，得到模型的预测结果 outputs</span></span><br><span class="line">        loss = cost(outputs, labels)    <span class="comment"># 计算模型预测与真实标签之间的损失</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 反向传播和优化</span></span><br><span class="line">        optimizer.zero_grad()   <span class="comment"># 清零梯度，以便在下一次反向传播中不累积之前的梯度</span></span><br><span class="line">        loss.backward()     <span class="comment"># 进行反向传播，计算梯度</span></span><br><span class="line">        optimizer.step()    <span class="comment"># 根据梯度更新（优化）模型参数</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 定期输出训练信息</span></span><br><span class="line">        <span class="comment"># 在每经过一定数量的批次后，输出当前训练轮次、总周轮数、当前批次、总批次数和损失值</span></span><br><span class="line">        <span class="keyword">if</span> (i+<span class="number">1</span>) % <span class="number">400</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span> (<span class="string">&#x27;Epoch [&#123;&#125;/&#123;&#125;], Step [&#123;&#125;/&#123;&#125;], Loss: &#123;:.4f&#125;&#x27;</span> </span><br><span class="line">                           .<span class="built_in">format</span>(epoch+<span class="number">1</span>, num_epochs, i+<span class="number">1</span>, total_step, loss.item()))</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>在内部循环<code>for i, (images, labels) in enumerate(train_loader):</code>中<code>enumerate(train_loader)</code> 返回一个可迭代的对象，其中包含每个批次的图像和标签。</p>
</li>
<li>
<p><code>images = images.to(device)</code> 和 <code>labels = labels.to(device)</code>：将加载的图像和标签移动到设备（通常是 GPU），以便在设备上执行模型的前向和后向传播。</p>
</li>
<li>
<p>对初学者而言，“定期输出训练信息”部分的代码用<code>print</code>输出即可，后期熟练了可以尝试用<code>tqdm</code>库显示进度条。这不是本文重点，有兴趣的可以自行了解。</p>
</li>
</ul>
<hr>
<p>训练时输出的结果：<br>
<img src="https://s2.loli.net/2024/12/26/iecCf3X6SpkQIz4.png" alt=""></p>
<p>938 跟我们之前手动计算的总批次数（步数）数是吻合的。</p>
<h2 id="8-测试">8. 测试</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad():   <span class="comment"># 指示 PyTorch 在接下来的代码块中不要计算梯度</span></span><br><span class="line">    <span class="comment"># 初始化计数器</span></span><br><span class="line">    correct = <span class="number">0</span>     <span class="comment"># 正确分类的样本数</span></span><br><span class="line">    total = <span class="number">0</span>       <span class="comment"># 总样本数</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历测试数据集的每个批次</span></span><br><span class="line">    <span class="keyword">for</span> images, labels <span class="keyword">in</span> test_loader:</span><br><span class="line">        <span class="comment"># 将加载的图像和标签移动到设备（通常是 GPU）上</span></span><br><span class="line">        images = images.to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 模型预测</span></span><br><span class="line">        outputs = model(images)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算准确率</span></span><br><span class="line">        <span class="comment"># 从模型输出中获取每个样本预测的类别</span></span><br><span class="line">        _, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 累积总样本数</span></span><br><span class="line">        total += labels.size(<span class="number">0</span>)</span><br><span class="line">        <span class="comment"># 累积正确分类的样本数</span></span><br><span class="line">        correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 输出准确率，正确的 / 总的</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Accuracy of the network on the 10000 test images: &#123;&#125; %&#x27;</span>.<span class="built_in">format</span>(<span class="number">100</span> * correct / total))</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>在测试阶段，我们通常不需要计算梯度，以提高内存效率。</p>
</li>
<li>
<p>注意看 <code>_, predicted = torch.max(outputs.data, 1)</code> 中的 <code>torch.max(xxx, 1)</code>表示对于每个输入 <code>xxx</code> 而言，<code>torch.max</code> 返回一个元组，其中包含两个张量，第一个张量是最大值，第二个张量是最大值所在的索引（也就是属于哪一类）。<br>
举个例子，在图像处理中，神经网络通常输出一个二维张量。什么样的二维张量呢？在3分类问题中输出二维张量：</p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor(<span class="string">[[0.1, 0.8, 0.3],</span></span><br><span class="line"><span class="string">        [0.4, 0.2, 0.9],</span></span><br><span class="line"><span class="string">        [0.7, 0.5, 0.2],</span></span><br><span class="line"><span class="string">        [0.6, 0.2, 0.4]]</span>)</span><br></pre></td></tr></table></figure>
<p>上面的二维张量，由 4 个长度为 3 的一维张量构成。<code>torch.max(xxx, 1)</code>在每一行中寻找最大值。<br>
<code>torch.max(xxx, 1)</code>返回结果为元组：</p>
<figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(tensor([<span class="number">0.8</span>, <span class="number">0.9</span>, <span class="number">0.7</span>, <span class="number">0.6</span>]), <span class="built_in">tensor</span>([<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>]))</span><br></pre></td></tr></table></figure>
<p>其中，0.8, 0.9, 0.7, 0.6 分别为属于索引（类别）1, 2, 0, 0 的概率（或得分）。</p>
</li>
<li>
<p>而 <code>_, predicted = torch.max(outputs.data, 1)</code> 中的 <code>_</code> 。它是一个通常用作占位符的变量名。在 Python 中，通常使用 <code>_</code> 表示一个临时或不使用的变量。在本例中，我们不要属于索引（类别）的概率（或得分），只要最终结果，即属于哪个索引（类别），把它的值赋给<code>predicted</code><br>
测试阶段运行的结果：<br>
<img src="https://s2.loli.net/2024/12/26/DI6rmZHU3cbkysE.png" alt=""><br>
可以看到达到了99.12%</p>
</li>
</ul>
<hr>
<p>以上，就是从0开始敲LeNet5的全部过程。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://haydenzhy.github.io/">梨花先雪</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://haydenzhy.github.io/post/1b5c5745">https://haydenzhy.github.io/post/1b5c5745</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://HaydenZHY.github.io" target="_blank">梨花先雪</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/PyTorch/">PyTorch</a><a class="post-meta__tags" href="/tags/LeNet5/">LeNet5</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/HaydenZHY/jsdelivr@main/image/avatar/avatar2.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/post/5dcf0f53" title="entertainment"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">entertainment</div></div></a></div><div class="next-post pull-right"><a href="/post/91cba6d6" title="AlexNet 图像分类（PyTorch框架）"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">AlexNet 图像分类（PyTorch框架）</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/post/91cba6d6" title="AlexNet 图像分类（PyTorch框架）"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-26</div><div class="title">AlexNet 图像分类（PyTorch框架）</div></div></a></div></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://cdn.jsdelivr.net/gh/HaydenZHY/jsdelivr@main/image/avatar/avatar2.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">梨花先雪</div><div class="author-info__description">言必信，行必果</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">50</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">63</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/HaydenZHY"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/HaydenZHY" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:243038409@qq.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">Welcome to my Blog !</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">手撸代码：从零开始的 LeNet5 图像分类（PyTorch 框架） </span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%91%98%E8%A6%81%EF%BC%9A"><span class="toc-number">1.1.</span> <span class="toc-text">摘要：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%BC%95%E5%85%A5%E5%BA%93%EF%BC%88Import-the-Libraries%EF%BC%89"><span class="toc-number">1.2.</span> <span class="toc-text">1. 引入库（Import the Libraries）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E9%80%89%E6%8B%A9%E5%9C%A8%E5%93%AA%E4%B8%AA%E8%AE%BE%E5%A4%87%E4%B8%8A%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%EF%BC%88GPU%E6%88%96CPU%EF%BC%89"><span class="toc-number">1.3.</span> <span class="toc-text">2. 选择在哪个设备上训练模型（GPU或CPU）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E8%AE%A4%E8%AF%86%E7%BD%91%E7%BB%9C"><span class="toc-number">1.4.</span> <span class="toc-text">3. 认识网络</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%881%EF%BC%89%E5%8D%B7%E7%A7%AF%E5%B1%821%EF%BC%9A%E6%8F%90%E5%8F%96%E4%BD%8E%E7%BA%A7%E7%89%B9%E5%BE%81"><span class="toc-number">1.4.1.</span> <span class="toc-text">（1）卷积层1：提取低级特征</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#a-%E7%AC%AC%E4%B8%80%E6%AC%A1%E5%8D%B7%E7%A7%AF"><span class="toc-number">1.4.1.1.</span> <span class="toc-text">a) 第一次卷积</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#b-%E6%89%B9%E5%BD%92%E4%B8%80%E5%8C%96"><span class="toc-number">1.4.1.2.</span> <span class="toc-text">b) 批归一化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#c-ReLU%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0"><span class="toc-number">1.4.1.3.</span> <span class="toc-text">c) ReLU激活函数</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%882%EF%BC%89%E4%B8%8B%E9%87%87%E6%A0%B7"><span class="toc-number">1.4.2.</span> <span class="toc-text">（2）下采样</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%883%EF%BC%89%E5%8D%B7%E7%A7%AF%E5%B1%822%EF%BC%9A%E6%8F%90%E5%8F%96%E9%AB%98%E7%BA%A7%E7%89%B9%E5%BE%81"><span class="toc-number">1.4.3.</span> <span class="toc-text">（3）卷积层2：提取高级特征</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#a-%E7%AC%AC%E4%BA%8C%E6%AC%A1%E5%8D%B7%E7%A7%AF"><span class="toc-number">1.4.3.1.</span> <span class="toc-text">a) 第二次卷积</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#b-%E6%89%B9%E5%BD%92%E4%B8%80%E5%8C%96-ReLU"><span class="toc-number">1.4.3.2.</span> <span class="toc-text">b) 批归一化+ReLU</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%884%EF%BC%89%E4%B8%8B%E9%87%87%E6%A0%B7"><span class="toc-number">1.4.4.</span> <span class="toc-text">（4）下采样</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%885%EF%BC%89%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%821"><span class="toc-number">1.4.5.</span> <span class="toc-text">（5）全连接层1</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%886%EF%BC%89%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%822"><span class="toc-number">1.4.6.</span> <span class="toc-text">（6）全连接层2</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%887%EF%BC%89%E9%AB%98%E6%96%AF%E8%BF%9E%E6%8E%A5%EF%BC%88%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%823%EF%BC%89"><span class="toc-number">1.4.7.</span> <span class="toc-text">（7）高斯连接（全连接层3）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E6%90%AD%E5%BB%BA%E7%BD%91%E7%BB%9C"><span class="toc-number">1.5.</span> <span class="toc-text">4. 搭建网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E5%87%86%E5%A4%87%EF%BC%88%E5%8A%A0%E8%BD%BD%EF%BC%89%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.6.</span> <span class="toc-text">5. 准备（加载）数据集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-%E8%AE%BE%E7%BD%AE%E8%B6%85%E5%8F%82%E6%95%B0"><span class="toc-number">1.7.</span> <span class="toc-text">6. 设置超参数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%881%EF%BC%89%E5%88%9B%E5%BB%BA-LeNet5-%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.7.1.</span> <span class="toc-text">（1）创建 LeNet5 模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%882%EF%BC%89%E5%88%9B%E5%BB%BA%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">1.7.2.</span> <span class="toc-text">（2）创建损失函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%883%EF%BC%89%E5%88%9B%E5%BB%BA%E4%BC%98%E5%8C%96%E5%99%A8"><span class="toc-number">1.7.3.</span> <span class="toc-text">（3）创建优化器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%884%EF%BC%89%E7%A1%AE%E5%AE%9A%E6%AF%8F%E8%BD%AE%E5%85%B1%E9%9C%80%E5%87%A0%E6%AD%A5"><span class="toc-number">1.7.4.</span> <span class="toc-text">（4）确定每轮共需几步</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-%E8%AE%AD%E7%BB%83"><span class="toc-number">1.8.</span> <span class="toc-text">7. 训练</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-%E6%B5%8B%E8%AF%95"><span class="toc-number">1.9.</span> <span class="toc-text">8. 测试</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/post/undefined" title="代理配置 Git 使用 Clash 代理">代理配置 Git 使用 Clash 代理</a><time datetime="2025-03-01T00:41:48.000Z" title="发表于 2025-03-01 08:41:48">2025-03-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/post/2161ae63" title="Anaconda新手安装和配置环境创建">Anaconda新手安装和配置环境创建</a><time datetime="2025-02-25T13:07:49.000Z" title="发表于 2025-02-25 21:07:49">2025-02-25</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/post/c06de4d5" title="工具箱">工具箱</a><time datetime="2025-02-24T02:05:05.000Z" title="发表于 2025-02-24 10:05:05">2025-02-24</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/post/aaf29fca" title="电脑基础操作">电脑基础操作</a><time datetime="2025-02-23T14:14:23.000Z" title="发表于 2025-02-23 22:14:23">2025-02-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/post/6e3f7550" title="VSCode中运行Python程序">VSCode中运行Python程序</a><time datetime="2025-02-23T09:42:44.000Z" title="发表于 2025-02-23 17:42:44">2025-02-23</time></div></div></div></div></div></div></main><footer id="footer" style="background: #626079"><div id="footer-wrap"><div class="copyright">&copy;2024 - 2025 By 梨花先雪</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="chat-btn" type="button" title="聊天"><i class="fas fa-sms"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="/js/tw_cn.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>(()=>{
  const getGiscusTheme = theme => {
    return theme === 'dark' ? 'dark' : 'light'
  }

  const loadGiscus = () => {
    const config = Object.assign({
      src: 'https://giscus.app/client.js',
      'data-repo': 'HaydenZHY/HaydenZHY.github.io',
      'data-repo-id': 'R_kgDOMtPJmQ',
      'data-category-id': 'DIC_kwDOMtPJmc4ClrGo',
      'data-mapping': 'pathname',
      'data-theme': getGiscusTheme(document.documentElement.getAttribute('data-theme')),
      'data-reactions-enabled': '1',
      crossorigin: 'anonymous',
      async: true
    },null)

    const ele = document.createElement('script')
    for (let key in config) {
      ele.setAttribute(key, config[key])
    }
    document.getElementById('giscus-wrap').appendChild(ele)
  }

  const changeGiscusTheme = theme => {
    const sendMessage = message => {
      const iframe = document.querySelector('iframe.giscus-frame')
      if (!iframe) return
      iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app')
    }

    sendMessage({
      setConfig: {
        theme: getGiscusTheme(theme)
      }
    });
  }

  btf.addGlobalFn('themeChange', changeGiscusTheme, 'giscus')

  if ('Giscus' === 'Giscus' || !false) {
    if (false) btf.loadComment(document.getElementById('giscus-wrap'), loadGiscus)
    else loadGiscus()
  } else {
    window.loadOtherComment= loadGiscus
  }
})()</script></div><script id="canvas_nest" defer="defer" color="121,206,226" opacity="0.7" zIndex="-1" count="88" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = true;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/click-heart.min.js" async="async" mobile="true"></script><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["link[rel=\"canonical\"]","meta[property=\"og:image\"]","meta[property=\"og:title\"]","meta[property=\"og:url\"]","head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"]):not([href="/movies/"]):not([href="/books/"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener
  btf.removeGlobalFnEvent('pjax')
  btf.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404')
  }
})</script></div><!-- hexo injector body_end start --><script data-pjax>
  function butterfly_clock_anzhiyu_injector_config(){
    var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
    var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img class="entered loading" id="card-clock-loading" src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading"/></div></div></div></div></div>';
    console.log('已挂载butterfly_clock_anzhiyu')
    if(parent_div_git) {
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var qweather_key = 'a996012aef93459d8c1f716106a6a684';
  var gaud_map_key = 'd85e2aaaa9c353eeacde11351c3f7484';
  var baidu_ak_key = 'undefined';
  var flag = 0;
  var clock_rectangle = '112.982279,28.19409';
  var clock_default_rectangle_enable = 'false';

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_clock_anzhiyu_injector_config();
  }
  else if (epage === cpage){
    butterfly_clock_anzhiyu_injector_config();
  }
  </script><script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script><script data-pjax src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.js"></script><!-- hexo injector body_end end --></body></html>